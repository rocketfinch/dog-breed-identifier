{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fa53a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 06:14:54.556009: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 06:14:55.044342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/corey/.local/lib/python3.10/site-packages/cv2/../../lib64::/home/corey/miniconda3/envs/tf/lib/:/home/corey/miniconda3/envs/tf/lib/\n",
      "2022-12-12 06:14:55.044390: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/corey/.local/lib/python3.10/site-packages/cv2/../../lib64::/home/corey/miniconda3/envs/tf/lib/:/home/corey/miniconda3/envs/tf/lib/\n",
      "2022-12-12 06:14:55.044394: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#dog breed indentifier using CNN\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "# from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications import xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "# from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692b7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = './results/'\n",
    "IMG_SIZE = 299\n",
    "\n",
    "BATCH_SIZE_PRE = 32\n",
    "BATCH_SIZE_FINE = 16\n",
    "EPOCHS_PRE = 5\n",
    "EPOCHS_PRE = 50\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48c716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image4d_from_file(filename:str):\n",
    "    image = cv2.imread(filename, cv2.IMREAD_COLOR).astype('float32')\n",
    "    print(\"image type:\", type(image))\n",
    "    image_4d = np.expand_dims(image, axis=0)\n",
    "    print(\"image_4d:\", image_4d.shape)\n",
    "    return image_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b67fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavily inspired by Xception-with-Your-Own-Dataset implementation of \n",
    "def generator_from_filenames_and_labels(filenames, labels, batch_size, input_size=(299,299)):\n",
    "    num_files = len(filenames)\n",
    "    while 1:\n",
    "        permutation = np.random.permutation(num_files)\n",
    "        inputs_shuffled = filenames[permutation]\n",
    "        labels_shuffled = labels[permutation]\n",
    "        for i in range(0, numsamples, batch_size):\n",
    "            inputs = list(map(lambda x: image.load_img(x, target_size=input_size), filenames[i:i+batch_size]))\n",
    "            inputs = np.array(list(map(lambda x: image.img_to_array(x))))\n",
    "            inputs = pre_process_inputs(inputs)\n",
    "            yield (inputs, labels[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7096ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18680 images belonging to 172 classes.\n",
      "Found 18680 images belonging to 172 classes.\n",
      "Found 9355 images belonging to 172 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "    rotation_range = 10,\n",
    "    horizontal_flip = True,\n",
    "    validation_split = 0.2)\n",
    "\n",
    "train_pre_generator = train_datagen.flow_from_directory(\n",
    "    directory = \"./data/fusion/train/\",\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = BATCH_SIZE_PRE,\n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "train_fine_generator = train_datagen.flow_from_directory(\n",
    "    directory = \"./data/fusion/train/\",\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = BATCH_SIZE_FINE,\n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory = \"./data/fusion/test/\",\n",
    "    batch_size = BATCH_SIZE_FINE,\n",
    "    class_mode = \"categorical\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c62dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Importing the dataset\n",
    "# dog_breed_name = pd.read_csv('./data/labels_original.csv')\n",
    "# dog_breed_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3620d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find files in the directory\n",
    "# images_train = os.listdir(\"./data/fusion/train/\")\n",
    "# # import test data set\n",
    "# image_test = os.listdir(\"./data/fusion/test/\")\n",
    "\n",
    "# # from https://stackoverflow.com/questions/2632205/how-to-count-the-number-of-files-in-a-directory-using-python\n",
    "# num_images_train = len([name for name in os.listdir('./data/fusion/train/') if os.path.isfile(name)])\n",
    "# num_images_test = len([name for name in os.listdir('./data/fusion/test/') if os.path.isfile(name)])\n",
    "\n",
    "# print(num_images_train)\n",
    "# print(num_images_test)\n",
    "# print(len(images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ba8645c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create target variable\n",
    "# dog_breed_name['target'] = dog_breed_name['breed'].astype('category').cat.codes\n",
    "# dog_breed_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ad9474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_breeds: 172\n"
     ]
    }
   ],
   "source": [
    "# dog_breed_dict = {}\n",
    "# for i, breed in enumerate(dog_breed_name['breed'].unique()):\n",
    "#     dog_breed_dict[breed] = i\n",
    "    \n",
    "# num_breeds = len(dog_breed_name['breed'].unique())\n",
    "# print(\"num_breeds:\", num_breeds)\n",
    "\n",
    "assert len(os.listdir('./data/fusion/train/')) == len(os.listdir('./data/fusion/test/'))\n",
    "num_breeds = len(os.listdir('./data/fusion/train/')) - 1\n",
    "print(\"num_breeds:\", num_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fe43995",
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_base_model = xception.Xception(include_top=False,\n",
    "                                        weights='imagenet',\n",
    "                                        input_shape=(299,299,3))\n",
    "\n",
    "x_base_xception = xception_base_model.output\n",
    "x_avg_pooling_xception = GlobalAveragePooling2D()(x_base_xception)\n",
    "x_first_fc_xception = Dense(1024, activation='relu')(x_avg_pooling_xception)\n",
    "x_last_fc_xception = Dense(num_breeds, activation='softmax')(x_first_fc_xception)\n",
    "\n",
    "xception_custom_model = Model(inputs=xception_base_model.inputs, outputs=x_last_fc_xception)\n",
    "\n",
    "# xception_custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a27eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50116/97229840.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_train_pre = xception_custom_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 06:22:23.690078: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 34329984 exceeds 10% of free system memory.\n",
      "2022-12-12 06:22:25.328106: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 34329984 exceeds 10% of free system memory.\n",
      "2022-12-12 06:22:25.490920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2022-12-12 06:22:25.626303: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-12 06:22:25.626681: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-12 06:22:25.626689: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:85] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-12-12 06:22:25.627022: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-12 06:22:25.627061: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-12-12 06:22:25.682756: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 34329984 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "#Train model - freeze body layers first\n",
    "for layer in xception_base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "xception_custom_model.compile(optimizer=SGD(momentum=MOMENTUM), loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "model_train_pre = xception_custom_model.fit_generator(\n",
    "    generator = train_pre_generator,\n",
    "    steps_per_epoch = (train_pre_generator.n//train_pre_generator.batch_size),\n",
    "    epochs = EPOCHS_PRE,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = (test_generator.n//test_generator.batch_size),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xception_custom_model.save(os.path.join(RESULTS_DIR, 'model_pre.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d611495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model - train all layers\n",
    "for layer in xception_base_model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "xception_custom_model.compile(optimizer=SGD(momentum=0.9), loss=categorical_crossentropy, metrics=['accuracy'] )\n",
    "\n",
    "model_train_fine = xception_custom_model.fit_generator(\n",
    "    generator = train_fine_generator,\n",
    "    steps_per_epoch = (train_fine_generator.n//train_fine_generator.batch_size),\n",
    "    epochs = EPOCHS_FINE,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = (test_generator.n//test_generator.batch_size),\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "xception_custom_model.save(os.path.join(RESULTS_DIR, 'model_fine.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def image_predict_from_model(filename:str):\n",
    "#     image_4d = read_image_4d(filename)\n",
    "#     preprocessed_image = preprocess_input(raw_image)\n",
    "#     prediction_probs = xception_model.predict_generator(preprocessed_image)\n",
    "#     best_prediction = np.argmax(prediction_probs)\n",
    "    \n",
    "# #     features = xception_models.predict(image)\n",
    "# #     return features.reshape(1, 7*7*512)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
